Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/logs/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr/18 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr/18 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr/18/initiation_set_plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr/18/value_function_plots 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr/18/accepted_events 
Successfully created the directory /ifs/CS/replicated/home/npermpre/hrl-with-dsg/plots/noOptionFilitering_keyDoorRoomConds_CNNInit_ImaginaryLUT_noChainLastOption_NoTrajSegment_NewEventCloseness_InventoryStr/18/rejected_events 
Creating classifier of type cnn
Creating rainbow with sigma=0.5
Created model-free option global-option with option_idx=0
[DSGTrainer] Adding new SalientEvent  SE([1 1])
[Seed=18] Device count: 1 Device Name: NVIDIA GeForce RTX 2080 Ti
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 0 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: 19.97501694317907
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 1 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -80.91289247685927
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 2 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -91.31254702154547
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 3 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -107.42522032896522
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 4 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -120.29142763465643
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 5 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -133.32706773187965
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 6 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -127.27904751617461
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 7 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -153.1968523208052
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 8 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -134.86252414199407
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 9 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -162.79129714518785
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 10 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -162.9711506748572
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 11 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -163.25954287673812
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 12 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -153.13912664423697
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 13 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -175.08487224028795
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 14 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -169.94317221269011
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 15 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -157.9700351586216
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 16 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -165.3031251002103
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 17 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -152.57930680387653
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 18 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -187.49851611070335
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 19 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -182.66893219202757
Took 44.54375767707825s to update distance table with 20040 states and events {SE([1 1]), None}
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 20 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -161.97898311191966
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 21 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -176.03769353637472
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 22 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -194.20317882625386
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 23 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -190.73586902581155
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 24 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -189.0217357915826
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 25 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -188.37889407819603
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 26 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -187.7504072948359
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 27 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 3.0	IntrinsicReward: -202.12033144384623
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 28 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -192.56231277040206
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 29 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -176.3262157366844
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 30 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -208.6079940237105
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 31 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -208.97450934210792
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 32 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -179.22577967052348
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 33 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -192.99303274881095
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 34 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 2.0	IntrinsicReward: -203.74000585777685
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 35 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -195.64294489473104
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 36 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -198.96167771262117
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 37 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 0.0	IntrinsicReward: -208.96727573499084
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 38 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 1.0	IntrinsicReward: -200.13957745180232
<hrl.agent.dsg.dsg.SkillGraphAgent object at 0x153338168160>
================================================================================
[Expansion] Episode: 39 Step: 0
================================================================================
Attempting to expand SE([1 1])
[RND Rollout] Reward: 2.0	IntrinsicReward: -211.85643596062437
Took 35.761064529418945s to update distance table with 20040 states and events {SE([1 1]), None}
[RND Rollout] Reward: 2.0	IntrinsicReward: -216.64176945993677
Took 0.059747934341430664s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 1.0	IntrinsicReward: -196.72423077188432
Took 0.03873419761657715s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -210.3411544689443
Took 0.09589099884033203s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 2.0	IntrinsicReward: -191.39424464851618
Took 0.05494856834411621s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 1.0	IntrinsicReward: -211.64661315921694
Took 0.024497032165527344s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -219.91075088526122
Took 0.07330965995788574s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 4.0	IntrinsicReward: -183.52056880039163
Took 0.03326606750488281s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 1.0	IntrinsicReward: -207.86829226883128
Took 0.06091904640197754s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 2.0	IntrinsicReward: -211.61606014729477
Took 0.0786280632019043s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 1.0	IntrinsicReward: -207.0312108893413
Took 0.02142810821533203s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 1.0	IntrinsicReward: -207.28017555263068
Took 0.05537295341491699s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 1.0	IntrinsicReward: -235.48898275196552
Took 0.10020923614501953s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -227.11023008008488
Took 0.07766032218933105s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 1.0	IntrinsicReward: -193.27153408894083
Took 0.03576016426086426s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -182.68223380605923
Took 0.05232858657836914s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 1.0	IntrinsicReward: -239.8276165984571
Took 0.016015291213989258s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 4.0	IntrinsicReward: -209.28727236005943
Took 0.05430865287780762s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 1.0	IntrinsicReward: -224.9611417381093
Took 0.020719289779663086s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -221.72362205246463
Took 0.018755197525024414s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -222.65518262638943
Took 0.14800739288330078s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 3.0	IntrinsicReward: -213.7392010431504
Took 0.03763985633850098s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 1.0	IntrinsicReward: -210.23719055741094
Took 0.16456246376037598s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 1.0	IntrinsicReward: -234.37540960591286
Took 0.17840576171875s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 5.0	IntrinsicReward: -225.83211572747678
Took 0.0178830623626709s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -212.84898186451755
Took 0.10694169998168945s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 2.0	IntrinsicReward: -220.20303649193374
Took 0.020998716354370117s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -236.4378368780017
Took 0.07024931907653809s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 1.0	IntrinsicReward: -236.06519941985607
Took 0.032288551330566406s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 1.0	IntrinsicReward: -208.47549881678424
Took 0.10232234001159668s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 3.0	IntrinsicReward: -226.6358782686293
Took 0.02116084098815918s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -248.72835107333958
Took 0.08344268798828125s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 4.0	IntrinsicReward: -242.98750916682184
Took 0.10003161430358887s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 3.0	IntrinsicReward: -229.61982380459085
Took 0.02200603485107422s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 3.0	IntrinsicReward: -217.53689429536462
Took 0.06708884239196777s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 4.0	IntrinsicReward: -240.731789491605
Took 0.015676259994506836s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 0.0	IntrinsicReward: -238.38842596695758
Took 0.06226396560668945s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 2.0	IntrinsicReward: -197.0368015106651
Took 0.019342899322509766s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 4.0	IntrinsicReward: -252.64540101587772
Took 0.016300678253173828s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 6.0	IntrinsicReward: -243.59472909010947
Took 0.015354394912719727s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 5.0	IntrinsicReward: -232.99971878970973
Took 0.03256082534790039s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 5.0	IntrinsicReward: -253.46579137363005
Took 0.017772912979125977s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 3.0	IntrinsicReward: -241.99552658293396
Took 0.18942737579345703s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 6.0	IntrinsicReward: -253.31045291706687
Took 0.03693556785583496s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 4.0	IntrinsicReward: -247.8097269386053
Took 0.0180509090423584s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 3.0	IntrinsicReward: -261.0301454695873
Took 0.06342697143554688s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 2.0	IntrinsicReward: -240.66557876579463
Took 0.11317205429077148s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 6.0	IntrinsicReward: -243.71255027176812
Took 0.08548092842102051s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 4.0	IntrinsicReward: -255.62701397796627
Took 0.018753528594970703s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 6.0	IntrinsicReward: -173.8153339382261
Took 0.020116806030273438s to update distance table with 1001 states and events {SE([1 1]), None}
[RND Rollout] Reward: 4.0	IntrinsicReward: -262.9200476631522
Took 0.0357203483581543s to update distance table with 1001 states and events {SE([1 1]), None}
[SE([1 1])]
> [0;32m/ifs/CS/replicated/home/npermpre/hrl-with-dsg/hrl/agent/dsg/trainer.py[0m(371)[0;36mgraph_consolidation_run_loop[0;34m()[0m
[0;32m    370 [0;31m[0;34m[0m[0m
[0m[0;32m--> 371 [0;31m            [0mprint[0m[0;34m([0m[0;34m"="[0m [0;34m*[0m [0;36m80[0m[0;34m)[0m[0;34m;[0m [0mprint[0m[0;34m([0m[0;34mf"[Consolidation] Episode: {current_episode} Step: {self.env.T}"[0m[0;34m)[0m[0;34m;[0m [0mprint[0m[0;34m([0m[0;34m"="[0m [0;34m*[0m [0;36m80[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[0;32m    372 [0;31m[0;34m[0m[0m
[0m
ipdb> 
